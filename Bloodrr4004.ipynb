{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "0087ce6f-4ceb-41b7-ae0d-fad40c62bce2",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "4004"
      ]
     },
     "execution_count": 1,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "4000+4"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "ffde7b4d-947d-4c14-8852-38a4336bffd0",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: requests in d:\\anapy\\lib\\site-packages (2.31.0)\n",
      "Requirement already satisfied: pandas in d:\\anapy\\lib\\site-packages (2.2.3)\n",
      "Requirement already satisfied: beautifulsoup4 in d:\\anapy\\lib\\site-packages (4.12.2)\n",
      "Requirement already satisfied: charset-normalizer<4,>=2 in d:\\anapy\\lib\\site-packages (from requests) (2.0.4)\n",
      "Requirement already satisfied: idna<4,>=2.5 in d:\\anapy\\lib\\site-packages (from requests) (3.4)\n",
      "Requirement already satisfied: urllib3<3,>=1.21.1 in d:\\anapy\\lib\\site-packages (from requests) (2.0.7)\n",
      "Requirement already satisfied: certifi>=2017.4.17 in d:\\anapy\\lib\\site-packages (from requests) (2024.2.2)\n",
      "Requirement already satisfied: numpy>=1.23.2 in d:\\anapy\\lib\\site-packages (from pandas) (1.26.4)\n",
      "Requirement already satisfied: python-dateutil>=2.8.2 in d:\\anapy\\lib\\site-packages (from pandas) (2.8.2)\n",
      "Requirement already satisfied: pytz>=2020.1 in d:\\anapy\\lib\\site-packages (from pandas) (2023.3.post1)\n",
      "Requirement already satisfied: tzdata>=2022.7 in d:\\anapy\\lib\\site-packages (from pandas) (2023.3)\n",
      "Requirement already satisfied: soupsieve>1.2 in d:\\anapy\\lib\\site-packages (from beautifulsoup4) (2.5)\n",
      "Requirement already satisfied: six>=1.5 in d:\\anapy\\lib\\site-packages (from python-dateutil>=2.8.2->pandas) (1.16.0)\n"
     ]
    },
    {
     "ename": "ValueError",
     "evalue": "136 columns passed, passed data had 9 columns",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mAssertionError\u001b[0m                            Traceback (most recent call last)",
      "File \u001b[1;32mD:\\anapy\\Lib\\site-packages\\pandas\\core\\internals\\construction.py:939\u001b[0m, in \u001b[0;36m_finalize_columns_and_data\u001b[1;34m(content, columns, dtype)\u001b[0m\n\u001b[0;32m    938\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[1;32m--> 939\u001b[0m     columns \u001b[38;5;241m=\u001b[39m _validate_or_indexify_columns(contents, columns)\n\u001b[0;32m    940\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m \u001b[38;5;167;01mAssertionError\u001b[39;00m \u001b[38;5;28;01mas\u001b[39;00m err:\n\u001b[0;32m    941\u001b[0m     \u001b[38;5;66;03m# GH#26429 do not raise user-facing AssertionError\u001b[39;00m\n",
      "File \u001b[1;32mD:\\anapy\\Lib\\site-packages\\pandas\\core\\internals\\construction.py:986\u001b[0m, in \u001b[0;36m_validate_or_indexify_columns\u001b[1;34m(content, columns)\u001b[0m\n\u001b[0;32m    984\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m is_mi_list \u001b[38;5;129;01mand\u001b[39;00m \u001b[38;5;28mlen\u001b[39m(columns) \u001b[38;5;241m!=\u001b[39m \u001b[38;5;28mlen\u001b[39m(content):  \u001b[38;5;66;03m# pragma: no cover\u001b[39;00m\n\u001b[0;32m    985\u001b[0m     \u001b[38;5;66;03m# caller's responsibility to check for this...\u001b[39;00m\n\u001b[1;32m--> 986\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mAssertionError\u001b[39;00m(\n\u001b[0;32m    987\u001b[0m         \u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;132;01m{\u001b[39;00m\u001b[38;5;28mlen\u001b[39m(columns)\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m columns passed, passed data had \u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[0;32m    988\u001b[0m         \u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;132;01m{\u001b[39;00m\u001b[38;5;28mlen\u001b[39m(content)\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m columns\u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[0;32m    989\u001b[0m     )\n\u001b[0;32m    990\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m is_mi_list:\n\u001b[0;32m    991\u001b[0m     \u001b[38;5;66;03m# check if nested list column, length of each sub-list should be equal\u001b[39;00m\n",
      "\u001b[1;31mAssertionError\u001b[0m: 136 columns passed, passed data had 9 columns",
      "\nThe above exception was the direct cause of the following exception:\n",
      "\u001b[1;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[2], line 32\u001b[0m\n\u001b[0;32m     29\u001b[0m         data\u001b[38;5;241m.\u001b[39mappend(row)\n\u001b[0;32m     31\u001b[0m \u001b[38;5;66;03m# Step 5: Create a pandas DataFrame\u001b[39;00m\n\u001b[1;32m---> 32\u001b[0m df \u001b[38;5;241m=\u001b[39m pd\u001b[38;5;241m.\u001b[39mDataFrame(data, columns\u001b[38;5;241m=\u001b[39mcolumns)\n\u001b[0;32m     34\u001b[0m \u001b[38;5;66;03m# Step 6: Save the DataFrame to a CSV file\u001b[39;00m\n\u001b[0;32m     35\u001b[0m df\u001b[38;5;241m.\u001b[39mto_csv(\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mblood_type_distribution.csv\u001b[39m\u001b[38;5;124m'\u001b[39m, index\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mFalse\u001b[39;00m)\n",
      "File \u001b[1;32mD:\\anapy\\Lib\\site-packages\\pandas\\core\\frame.py:851\u001b[0m, in \u001b[0;36mDataFrame.__init__\u001b[1;34m(self, data, index, columns, dtype, copy)\u001b[0m\n\u001b[0;32m    849\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m columns \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[0;32m    850\u001b[0m         columns \u001b[38;5;241m=\u001b[39m ensure_index(columns)\n\u001b[1;32m--> 851\u001b[0m     arrays, columns, index \u001b[38;5;241m=\u001b[39m nested_data_to_arrays(\n\u001b[0;32m    852\u001b[0m         \u001b[38;5;66;03m# error: Argument 3 to \"nested_data_to_arrays\" has incompatible\u001b[39;00m\n\u001b[0;32m    853\u001b[0m         \u001b[38;5;66;03m# type \"Optional[Collection[Any]]\"; expected \"Optional[Index]\"\u001b[39;00m\n\u001b[0;32m    854\u001b[0m         data,\n\u001b[0;32m    855\u001b[0m         columns,\n\u001b[0;32m    856\u001b[0m         index,  \u001b[38;5;66;03m# type: ignore[arg-type]\u001b[39;00m\n\u001b[0;32m    857\u001b[0m         dtype,\n\u001b[0;32m    858\u001b[0m     )\n\u001b[0;32m    859\u001b[0m     mgr \u001b[38;5;241m=\u001b[39m arrays_to_mgr(\n\u001b[0;32m    860\u001b[0m         arrays,\n\u001b[0;32m    861\u001b[0m         columns,\n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m    864\u001b[0m         typ\u001b[38;5;241m=\u001b[39mmanager,\n\u001b[0;32m    865\u001b[0m     )\n\u001b[0;32m    866\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n",
      "File \u001b[1;32mD:\\anapy\\Lib\\site-packages\\pandas\\core\\internals\\construction.py:520\u001b[0m, in \u001b[0;36mnested_data_to_arrays\u001b[1;34m(data, columns, index, dtype)\u001b[0m\n\u001b[0;32m    517\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m is_named_tuple(data[\u001b[38;5;241m0\u001b[39m]) \u001b[38;5;129;01mand\u001b[39;00m columns \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[0;32m    518\u001b[0m     columns \u001b[38;5;241m=\u001b[39m ensure_index(data[\u001b[38;5;241m0\u001b[39m]\u001b[38;5;241m.\u001b[39m_fields)\n\u001b[1;32m--> 520\u001b[0m arrays, columns \u001b[38;5;241m=\u001b[39m to_arrays(data, columns, dtype\u001b[38;5;241m=\u001b[39mdtype)\n\u001b[0;32m    521\u001b[0m columns \u001b[38;5;241m=\u001b[39m ensure_index(columns)\n\u001b[0;32m    523\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m index \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n",
      "File \u001b[1;32mD:\\anapy\\Lib\\site-packages\\pandas\\core\\internals\\construction.py:845\u001b[0m, in \u001b[0;36mto_arrays\u001b[1;34m(data, columns, dtype)\u001b[0m\n\u001b[0;32m    842\u001b[0m     data \u001b[38;5;241m=\u001b[39m [\u001b[38;5;28mtuple\u001b[39m(x) \u001b[38;5;28;01mfor\u001b[39;00m x \u001b[38;5;129;01min\u001b[39;00m data]\n\u001b[0;32m    843\u001b[0m     arr \u001b[38;5;241m=\u001b[39m _list_to_arrays(data)\n\u001b[1;32m--> 845\u001b[0m content, columns \u001b[38;5;241m=\u001b[39m _finalize_columns_and_data(arr, columns, dtype)\n\u001b[0;32m    846\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m content, columns\n",
      "File \u001b[1;32mD:\\anapy\\Lib\\site-packages\\pandas\\core\\internals\\construction.py:942\u001b[0m, in \u001b[0;36m_finalize_columns_and_data\u001b[1;34m(content, columns, dtype)\u001b[0m\n\u001b[0;32m    939\u001b[0m     columns \u001b[38;5;241m=\u001b[39m _validate_or_indexify_columns(contents, columns)\n\u001b[0;32m    940\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m \u001b[38;5;167;01mAssertionError\u001b[39;00m \u001b[38;5;28;01mas\u001b[39;00m err:\n\u001b[0;32m    941\u001b[0m     \u001b[38;5;66;03m# GH#26429 do not raise user-facing AssertionError\u001b[39;00m\n\u001b[1;32m--> 942\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mValueError\u001b[39;00m(err) \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01merr\u001b[39;00m\n\u001b[0;32m    944\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mlen\u001b[39m(contents) \u001b[38;5;129;01mand\u001b[39;00m contents[\u001b[38;5;241m0\u001b[39m]\u001b[38;5;241m.\u001b[39mdtype \u001b[38;5;241m==\u001b[39m np\u001b[38;5;241m.\u001b[39mobject_:\n\u001b[0;32m    945\u001b[0m     contents \u001b[38;5;241m=\u001b[39m convert_object_array(contents, dtype\u001b[38;5;241m=\u001b[39mdtype)\n",
      "\u001b[1;31mValueError\u001b[0m: 136 columns passed, passed data had 9 columns"
     ]
    }
   ],
   "source": [
    "# Install the necessary libraries if not already installed\n",
    "!pip install requests pandas beautifulsoup4\n",
    "\n",
    "import requests\n",
    "import pandas as pd\n",
    "from bs4 import BeautifulSoup\n",
    "\n",
    "# Step 1: Send a GET request to the Wikipedia page\n",
    "url = 'https://en.wikipedia.org/wiki/Blood_type_distribution_by_country'\n",
    "response = requests.get(url)\n",
    "\n",
    "# Step 2: Parse the page content\n",
    "soup = BeautifulSoup(response.content, 'html.parser')\n",
    "\n",
    "# Step 3: Find the specific table with the blood type distribution information\n",
    "# This is the table with the class 'wikitable' that contains the information we need\n",
    "table = soup.find('table', {'class': 'wikitable'})\n",
    "\n",
    "# Step 4: Extract the table data into a pandas DataFrame\n",
    "# We will iterate through the rows of the table to extract the headers and data\n",
    "columns = []\n",
    "for th in table.find_all('th'):\n",
    "    columns.append(th.get_text(strip=True))\n",
    "\n",
    "data = []\n",
    "for tr in table.find_all('tr')[1:]:  # Skipping the header row\n",
    "    row = [td.get_text(strip=True) for td in tr.find_all('td')]\n",
    "    if row:  # Ensure the row is not empty\n",
    "        data.append(row)\n",
    "\n",
    "# Step 5: Create a pandas DataFrame\n",
    "df = pd.DataFrame(data, columns=columns)\n",
    "\n",
    "# Step 6: Save the DataFrame to a CSV file\n",
    "df.to_csv('blood_type_distribution.csv', index=False)\n",
    "\n",
    "# Step 7: Display the first few rows of the DataFrame for verification\n",
    "df.head()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "35cd31e1-ef48-4ede-b033-23f08a467340",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Country/Dependency</th>\n",
       "      <th>Population[1]</th>\n",
       "      <th>O+</th>\n",
       "      <th>A+</th>\n",
       "      <th>B+</th>\n",
       "      <th>AB+</th>\n",
       "      <th>O−</th>\n",
       "      <th>A−</th>\n",
       "      <th>B−</th>\n",
       "      <th>AB−</th>\n",
       "      <th>...</th>\n",
       "      <th>Ukraine</th>\n",
       "      <th>United Arab Emirates</th>\n",
       "      <th>United Kingdom[70]</th>\n",
       "      <th>United States[71]</th>\n",
       "      <th>Uzbekistan[72]</th>\n",
       "      <th>Venezuela[73]</th>\n",
       "      <th>Vietnam</th>\n",
       "      <th>Yemen</th>\n",
       "      <th>Zimbabwe</th>\n",
       "      <th>World[74]</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>3,074,579</td>\n",
       "      <td>34.1%</td>\n",
       "      <td>31.2%</td>\n",
       "      <td>14.5%</td>\n",
       "      <td>5.2%</td>\n",
       "      <td>6.0%</td>\n",
       "      <td>5.5%</td>\n",
       "      <td>2.6%</td>\n",
       "      <td>0.9%</td>\n",
       "      <td></td>\n",
       "      <td>...</td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>43,576,691</td>\n",
       "      <td>40.0%</td>\n",
       "      <td>30.0%</td>\n",
       "      <td>15.0%</td>\n",
       "      <td>4.25%</td>\n",
       "      <td>6.6%</td>\n",
       "      <td>2.3%</td>\n",
       "      <td>1.1%</td>\n",
       "      <td>0.75%</td>\n",
       "      <td></td>\n",
       "      <td>...</td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>45,479,118</td>\n",
       "      <td>50.34%</td>\n",
       "      <td>31.09%</td>\n",
       "      <td>8.20%</td>\n",
       "      <td>2.16%</td>\n",
       "      <td>4.29%</td>\n",
       "      <td>2.98%</td>\n",
       "      <td>0.74%</td>\n",
       "      <td>0.20%</td>\n",
       "      <td></td>\n",
       "      <td>...</td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>3,021,324</td>\n",
       "      <td>29.0%</td>\n",
       "      <td>46.3%</td>\n",
       "      <td>12.0%</td>\n",
       "      <td>5.6%</td>\n",
       "      <td>2.0%</td>\n",
       "      <td>3.7%</td>\n",
       "      <td>1.0%</td>\n",
       "      <td>0.4%</td>\n",
       "      <td></td>\n",
       "      <td>...</td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>25,466,459</td>\n",
       "      <td>38.0%</td>\n",
       "      <td>32.0%</td>\n",
       "      <td>12.0%</td>\n",
       "      <td>4.0%</td>\n",
       "      <td>7.0%</td>\n",
       "      <td>6.0%</td>\n",
       "      <td>2.0%</td>\n",
       "      <td>1.0%</td>\n",
       "      <td></td>\n",
       "      <td>...</td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows × 136 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "  Country/Dependency Population[1]      O+     A+     B+    AB+     O−     A−  \\\n",
       "0          3,074,579         34.1%   31.2%  14.5%   5.2%   6.0%   5.5%   2.6%   \n",
       "1         43,576,691         40.0%   30.0%  15.0%  4.25%   6.6%   2.3%   1.1%   \n",
       "2         45,479,118        50.34%  31.09%  8.20%  2.16%  4.29%  2.98%  0.74%   \n",
       "3          3,021,324         29.0%   46.3%  12.0%   5.6%   2.0%   3.7%   1.0%   \n",
       "4         25,466,459         38.0%   32.0%  12.0%   4.0%   7.0%   6.0%   2.0%   \n",
       "\n",
       "      B− AB−  ... Ukraine United Arab Emirates United Kingdom[70]  \\\n",
       "0   0.9%      ...                                                   \n",
       "1  0.75%      ...                                                   \n",
       "2  0.20%      ...                                                   \n",
       "3   0.4%      ...                                                   \n",
       "4   1.0%      ...                                                   \n",
       "\n",
       "  United States[71] Uzbekistan[72] Venezuela[73] Vietnam Yemen Zimbabwe  \\\n",
       "0                                                                         \n",
       "1                                                                         \n",
       "2                                                                         \n",
       "3                                                                         \n",
       "4                                                                         \n",
       "\n",
       "  World[74]  \n",
       "0            \n",
       "1            \n",
       "2            \n",
       "3            \n",
       "4            \n",
       "\n",
       "[5 rows x 136 columns]"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import requests\n",
    "import pandas as pd\n",
    "from bs4 import BeautifulSoup\n",
    "\n",
    "# Step 1: Send a GET request to the Wikipedia page\n",
    "url = 'https://en.wikipedia.org/wiki/Blood_type_distribution_by_country'\n",
    "response = requests.get(url)\n",
    "\n",
    "# Step 2: Parse the page content\n",
    "soup = BeautifulSoup(response.content, 'html.parser')\n",
    "\n",
    "# Step 3: Find the specific table with the blood type distribution information\n",
    "# This is the table with the class 'wikitable' that contains the information we need\n",
    "table = soup.find('table', {'class': 'wikitable'})\n",
    "\n",
    "# Step 4: Extract the table headers\n",
    "columns = []\n",
    "for th in table.find_all('th'):\n",
    "    columns.append(th.get_text(strip=True))\n",
    "\n",
    "# Step 5: Extract the table data\n",
    "data = []\n",
    "for tr in table.find_all('tr')[1:]:  # Skipping the header row\n",
    "    row = [td.get_text(strip=True) for td in tr.find_all('td')]\n",
    "    if row:  # Ensure the row is not empty\n",
    "        data.append(row)\n",
    "\n",
    "# Step 6: Handle mismatched columns by ensuring rows have the same number of columns as the headers\n",
    "# If rows have fewer columns, fill them with empty strings\n",
    "max_columns = len(columns)\n",
    "for i in range(len(data)):\n",
    "    if len(data[i]) < max_columns:\n",
    "        data[i] += [''] * (max_columns - len(data[i]))\n",
    "\n",
    "# Step 7: Create a pandas DataFrame\n",
    "df = pd.DataFrame(data, columns=columns)\n",
    "\n",
    "# Step 8: Save the DataFrame to a CSV file\n",
    "df.to_csv('blood_type_distribution.csv', index=False)\n",
    "\n",
    "# Step 9: Display the first few rows of the DataFrame for verification\n",
    "df.head()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "d963b1dd-4896-40d1-b408-68e5f4381022",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Country/Dependency</th>\n",
       "      <th>Population[1]</th>\n",
       "      <th>O+</th>\n",
       "      <th>A+</th>\n",
       "      <th>B+</th>\n",
       "      <th>AB+</th>\n",
       "      <th>O−</th>\n",
       "      <th>A−</th>\n",
       "      <th>B−</th>\n",
       "      <th>AB−</th>\n",
       "      <th>...</th>\n",
       "      <th>Ukraine</th>\n",
       "      <th>United Arab Emirates</th>\n",
       "      <th>United Kingdom[70]</th>\n",
       "      <th>United States[71]</th>\n",
       "      <th>Uzbekistan[72]</th>\n",
       "      <th>Venezuela[73]</th>\n",
       "      <th>Vietnam</th>\n",
       "      <th>Yemen</th>\n",
       "      <th>Zimbabwe</th>\n",
       "      <th>World[74]</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>3,074,579</td>\n",
       "      <td>34.1%</td>\n",
       "      <td>31.2%</td>\n",
       "      <td>14.5%</td>\n",
       "      <td>5.2%</td>\n",
       "      <td>6.0%</td>\n",
       "      <td>5.5%</td>\n",
       "      <td>2.6%</td>\n",
       "      <td>0.9%</td>\n",
       "      <td></td>\n",
       "      <td>...</td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>43,576,691</td>\n",
       "      <td>40.0%</td>\n",
       "      <td>30.0%</td>\n",
       "      <td>15.0%</td>\n",
       "      <td>4.25%</td>\n",
       "      <td>6.6%</td>\n",
       "      <td>2.3%</td>\n",
       "      <td>1.1%</td>\n",
       "      <td>0.75%</td>\n",
       "      <td></td>\n",
       "      <td>...</td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>45,479,118</td>\n",
       "      <td>50.34%</td>\n",
       "      <td>31.09%</td>\n",
       "      <td>8.20%</td>\n",
       "      <td>2.16%</td>\n",
       "      <td>4.29%</td>\n",
       "      <td>2.98%</td>\n",
       "      <td>0.74%</td>\n",
       "      <td>0.20%</td>\n",
       "      <td></td>\n",
       "      <td>...</td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>3,021,324</td>\n",
       "      <td>29.0%</td>\n",
       "      <td>46.3%</td>\n",
       "      <td>12.0%</td>\n",
       "      <td>5.6%</td>\n",
       "      <td>2.0%</td>\n",
       "      <td>3.7%</td>\n",
       "      <td>1.0%</td>\n",
       "      <td>0.4%</td>\n",
       "      <td></td>\n",
       "      <td>...</td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>25,466,459</td>\n",
       "      <td>38.0%</td>\n",
       "      <td>32.0%</td>\n",
       "      <td>12.0%</td>\n",
       "      <td>4.0%</td>\n",
       "      <td>7.0%</td>\n",
       "      <td>6.0%</td>\n",
       "      <td>2.0%</td>\n",
       "      <td>1.0%</td>\n",
       "      <td></td>\n",
       "      <td>...</td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows × 136 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "  Country/Dependency Population[1]      O+     A+     B+    AB+     O−     A−  \\\n",
       "0          3,074,579         34.1%   31.2%  14.5%   5.2%   6.0%   5.5%   2.6%   \n",
       "1         43,576,691         40.0%   30.0%  15.0%  4.25%   6.6%   2.3%   1.1%   \n",
       "2         45,479,118        50.34%  31.09%  8.20%  2.16%  4.29%  2.98%  0.74%   \n",
       "3          3,021,324         29.0%   46.3%  12.0%   5.6%   2.0%   3.7%   1.0%   \n",
       "4         25,466,459         38.0%   32.0%  12.0%   4.0%   7.0%   6.0%   2.0%   \n",
       "\n",
       "      B− AB−  ... Ukraine United Arab Emirates United Kingdom[70]  \\\n",
       "0   0.9%      ...                                                   \n",
       "1  0.75%      ...                                                   \n",
       "2  0.20%      ...                                                   \n",
       "3   0.4%      ...                                                   \n",
       "4   1.0%      ...                                                   \n",
       "\n",
       "  United States[71] Uzbekistan[72] Venezuela[73] Vietnam Yemen Zimbabwe  \\\n",
       "0                                                                         \n",
       "1                                                                         \n",
       "2                                                                         \n",
       "3                                                                         \n",
       "4                                                                         \n",
       "\n",
       "  World[74]  \n",
       "0            \n",
       "1            \n",
       "2            \n",
       "3            \n",
       "4            \n",
       "\n",
       "[5 rows x 136 columns]"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import requests\n",
    "import pandas as pd\n",
    "from bs4 import BeautifulSoup\n",
    "\n",
    "# Step 1: Send a GET request to the Wikipedia page\n",
    "url = 'https://en.wikipedia.org/wiki/Blood_type_distribution_by_country'\n",
    "response = requests.get(url)\n",
    "\n",
    "# Step 2: Parse the page content\n",
    "soup = BeautifulSoup(response.content, 'html.parser')\n",
    "\n",
    "# Step 3: Find the specific table with the blood type distribution information\n",
    "# This is the table with the class 'wikitable' that contains the information we need\n",
    "table = soup.find('table', {'class': 'wikitable'})\n",
    "\n",
    "# Step 4: Extract the table headers\n",
    "columns = []\n",
    "for th in table.find_all('th'):\n",
    "    columns.append(th.get_text(strip=True))\n",
    "\n",
    "# Step 5: Extract the table data\n",
    "data = []\n",
    "for tr in table.find_all('tr')[1:]:  # Skipping the header row\n",
    "    row = [td.get_text(strip=True) for td in tr.find_all('td')]\n",
    "    if row:  # Ensure the row is not empty\n",
    "        data.append(row)\n",
    "\n",
    "# Step 6: Handle mismatched columns by ensuring rows have the same number of columns as the headers\n",
    "# If rows have fewer columns, fill them with empty strings\n",
    "max_columns = len(columns)\n",
    "for i in range(len(data)):\n",
    "    if len(data[i]) < max_columns:\n",
    "        data[i] += [''] * (max_columns - len(data[i]))\n",
    "\n",
    "# Step 7: Create a pandas DataFrame\n",
    "df = pd.DataFrame(data, columns=columns)\n",
    "\n",
    "# Step 8: Save the DataFrame to the specified location\n",
    "file_path = r'F:\\MLpractrice\\blood\\blood_type_distribution.csv'  # Make sure this folder exists\n",
    "df.to_csv(file_path, index=False)\n",
    "\n",
    "# Step 9: Display the first few rows of the DataFrame for verification\n",
    "df.head()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "045dc6e0-7fd2-49b9-9ec3-a2e476263d49",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Country/Dependency</th>\n",
       "      <th>Population[1]</th>\n",
       "      <th>O+</th>\n",
       "      <th>A+</th>\n",
       "      <th>B+</th>\n",
       "      <th>AB+</th>\n",
       "      <th>O−</th>\n",
       "      <th>A−</th>\n",
       "      <th>B−</th>\n",
       "      <th>AB−</th>\n",
       "      <th>...</th>\n",
       "      <th>Ukraine</th>\n",
       "      <th>United Arab Emirates</th>\n",
       "      <th>United Kingdom[70]</th>\n",
       "      <th>United States[71]</th>\n",
       "      <th>Uzbekistan[72]</th>\n",
       "      <th>Venezuela[73]</th>\n",
       "      <th>Vietnam</th>\n",
       "      <th>Yemen</th>\n",
       "      <th>Zimbabwe</th>\n",
       "      <th>World[74]</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>0 rows × 136 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "Empty DataFrame\n",
       "Columns: [Country/Dependency, Population[1], O+, A+, B+, AB+, O−, A−, B−, AB−, Albania[2], Algeria[3], Argentina[4], Armenia[5], Australia[6], Austria[7], Azerbaijan, Bahrain, Bangladesh[8], Belarus, Belgium[9], Bhutan[citation needed], Bolivia, Bosnia and Herzegovina, Brazil[10], Bulgaria, Burkina Faso[11], Cambodia, Cameroon[12], Canada[13], Chile[14], Colombia[15], Costa Rica[16], Croatia, Cuba, Cyprus[17], Czech Republic[18], Democratic Republic of the Congo, Denmark[19], Dominican Republic, Ecuador, Egypt[20], El Salvador[21], Estonia[22], Ethiopia, Fiji, Finland[23], France[24], Gabon[25], Georgia[26], Germany[27], Ghana, Greece, Guinea, Honduras, Hong Kong[28], Hungary, Iceland[29], India[30], Indonesia, Iran, Iraq, Ireland[31], Israel[32], Italy, Ivory Coast[33], Jamaica[34], Japan[35], Jordan[36], Kazakhstan, Kenya, Laos[37], Latvia, Lebanon, Libya, Liechtenstein, Lithuania, Luxembourg[38], Macao, Malaysia, Malta, Mauritania[39], Mauritius, Mexico[40], Moldova[41], Mongolia[42], Morocco, Myanmar, Namibia[43], Nepal, Netherlands[44], New Zealand[45], Nicaragua[46], Nigeria[47], North Korea, North Macedonia, Norway[48], Pakistan[citation needed], Papua New Guinea, Paraguay[49], ...]\n",
       "Index: []\n",
       "\n",
       "[0 rows x 136 columns]"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import requests\n",
    "import pandas as pd\n",
    "from bs4 import BeautifulSoup\n",
    "\n",
    "# Step 1: Send a GET request to the Wikipedia page\n",
    "url = 'https://en.wikipedia.org/wiki/Blood_type_distribution_by_country'\n",
    "response = requests.get(url)\n",
    "\n",
    "# Step 2: Parse the page content\n",
    "soup = BeautifulSoup(response.content, 'html.parser')\n",
    "\n",
    "# Step 3: Find the specific table with the blood type distribution information\n",
    "# This is the table with the class 'wikitable' that contains the information we need\n",
    "table = soup.find('table', {'class': 'wikitable'})\n",
    "\n",
    "# Step 4: Extract the table headers\n",
    "columns = []\n",
    "for th in table.find_all('th'):\n",
    "    columns.append(th.get_text(strip=True))\n",
    "\n",
    "# Step 5: Extract the table data\n",
    "data = []\n",
    "for tr in table.find_all('tr')[1:]:  # Skipping the header row\n",
    "    # Extract the cells in each row\n",
    "    cells = tr.find_all('td')\n",
    "    \n",
    "    # Ensure the row has enough cells (sometimes there can be merged cells)\n",
    "    if len(cells) > 0:\n",
    "        # Extract country name from the first cell (we assume it's in the first column)\n",
    "        country_name = cells[0].get_text(strip=True)\n",
    "        \n",
    "        # Extract the rest of the row data (percentage values)\n",
    "        row_data = [country_name] + [cell.get_text(strip=True) for cell in cells[1:]]\n",
    "        \n",
    "        # Append the row to data if it has the same number of columns\n",
    "        if len(row_data) == len(columns):\n",
    "            data.append(row_data)\n",
    "\n",
    "# Step 6: Create a pandas DataFrame\n",
    "df = pd.DataFrame(data, columns=columns)\n",
    "\n",
    "# Step 7: Save the DataFrame to the specified location\n",
    "file_path = r'F:\\MLpractrice\\blood\\blood_type_distribution.csv'  # Ensure this folder exists\n",
    "df.to_csv(file_path, index=False)\n",
    "\n",
    "# Step 8: Display the first few rows of the DataFrame for verification\n",
    "df.head()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "bcfecc52-b296-4c3c-adf6-938f2854ca50",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Total tables found: 3\n"
     ]
    },
    {
     "ename": "AttributeError",
     "evalue": "Can only use .str accessor with string values!",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mAttributeError\u001b[0m                            Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[7], line 20\u001b[0m\n\u001b[0;32m     16\u001b[0m df\u001b[38;5;241m.\u001b[39mhead()\n\u001b[0;32m     18\u001b[0m \u001b[38;5;66;03m# Step 6: Clean the dataframe\u001b[39;00m\n\u001b[0;32m     19\u001b[0m \u001b[38;5;66;03m# Remove the columns that contain footnotes or unwanted symbols\u001b[39;00m\n\u001b[1;32m---> 20\u001b[0m df\u001b[38;5;241m.\u001b[39mcolumns \u001b[38;5;241m=\u001b[39m df\u001b[38;5;241m.\u001b[39mcolumns\u001b[38;5;241m.\u001b[39mstr\u001b[38;5;241m.\u001b[39mreplace(\u001b[38;5;124mr\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124m\\\u001b[39m\u001b[38;5;124m[.*\u001b[39m\u001b[38;5;124m\\\u001b[39m\u001b[38;5;124m]\u001b[39m\u001b[38;5;124m'\u001b[39m, \u001b[38;5;124m'\u001b[39m\u001b[38;5;124m'\u001b[39m, regex\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mTrue\u001b[39;00m)  \u001b[38;5;66;03m# Remove footnote references\u001b[39;00m\n\u001b[0;32m     22\u001b[0m \u001b[38;5;66;03m# Step 7: Save the DataFrame to the specified location\u001b[39;00m\n\u001b[0;32m     23\u001b[0m file_path \u001b[38;5;241m=\u001b[39m \u001b[38;5;124mr\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mF:\u001b[39m\u001b[38;5;124m\\\u001b[39m\u001b[38;5;124mMLpractrice\u001b[39m\u001b[38;5;124m\\\u001b[39m\u001b[38;5;124mblood\u001b[39m\u001b[38;5;124m\\\u001b[39m\u001b[38;5;124mblood_type_distribution.csv\u001b[39m\u001b[38;5;124m'\u001b[39m  \u001b[38;5;66;03m# Ensure this folder exists\u001b[39;00m\n",
      "File \u001b[1;32mD:\\anapy\\Lib\\site-packages\\pandas\\core\\accessor.py:224\u001b[0m, in \u001b[0;36mCachedAccessor.__get__\u001b[1;34m(self, obj, cls)\u001b[0m\n\u001b[0;32m    221\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m obj \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[0;32m    222\u001b[0m     \u001b[38;5;66;03m# we're accessing the attribute of the class, i.e., Dataset.geo\u001b[39;00m\n\u001b[0;32m    223\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_accessor\n\u001b[1;32m--> 224\u001b[0m accessor_obj \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_accessor(obj)\n\u001b[0;32m    225\u001b[0m \u001b[38;5;66;03m# Replace the property with the accessor object. Inspired by:\u001b[39;00m\n\u001b[0;32m    226\u001b[0m \u001b[38;5;66;03m# https://www.pydanny.com/cached-property.html\u001b[39;00m\n\u001b[0;32m    227\u001b[0m \u001b[38;5;66;03m# We need to use object.__setattr__ because we overwrite __setattr__ on\u001b[39;00m\n\u001b[0;32m    228\u001b[0m \u001b[38;5;66;03m# NDFrame\u001b[39;00m\n\u001b[0;32m    229\u001b[0m \u001b[38;5;28mobject\u001b[39m\u001b[38;5;241m.\u001b[39m\u001b[38;5;21m__setattr__\u001b[39m(obj, \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_name, accessor_obj)\n",
      "File \u001b[1;32mD:\\anapy\\Lib\\site-packages\\pandas\\core\\strings\\accessor.py:191\u001b[0m, in \u001b[0;36mStringMethods.__init__\u001b[1;34m(self, data)\u001b[0m\n\u001b[0;32m    188\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21m__init__\u001b[39m(\u001b[38;5;28mself\u001b[39m, data) \u001b[38;5;241m-\u001b[39m\u001b[38;5;241m>\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[0;32m    189\u001b[0m     \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01mpandas\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mcore\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01marrays\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mstring_\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m StringDtype\n\u001b[1;32m--> 191\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_inferred_dtype \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_validate(data)\n\u001b[0;32m    192\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_is_categorical \u001b[38;5;241m=\u001b[39m \u001b[38;5;28misinstance\u001b[39m(data\u001b[38;5;241m.\u001b[39mdtype, CategoricalDtype)\n\u001b[0;32m    193\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_is_string \u001b[38;5;241m=\u001b[39m \u001b[38;5;28misinstance\u001b[39m(data\u001b[38;5;241m.\u001b[39mdtype, StringDtype)\n",
      "File \u001b[1;32mD:\\anapy\\Lib\\site-packages\\pandas\\core\\strings\\accessor.py:245\u001b[0m, in \u001b[0;36mStringMethods._validate\u001b[1;34m(data)\u001b[0m\n\u001b[0;32m    242\u001b[0m inferred_dtype \u001b[38;5;241m=\u001b[39m lib\u001b[38;5;241m.\u001b[39minfer_dtype(values, skipna\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mTrue\u001b[39;00m)\n\u001b[0;32m    244\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m inferred_dtype \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;129;01min\u001b[39;00m allowed_types:\n\u001b[1;32m--> 245\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mAttributeError\u001b[39;00m(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mCan only use .str accessor with string values!\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n\u001b[0;32m    246\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m inferred_dtype\n",
      "\u001b[1;31mAttributeError\u001b[0m: Can only use .str accessor with string values!"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "\n",
    "# Step 1: URL of the Wikipedia page\n",
    "url = 'https://en.wikipedia.org/wiki/Blood_type_distribution_by_country'\n",
    "\n",
    "# Step 2: Use pandas to directly read the table from the webpage\n",
    "tables = pd.read_html(url)\n",
    "\n",
    "# Step 3: Check how many tables are present\n",
    "print(f'Total tables found: {len(tables)}')\n",
    "\n",
    "# Step 4: Select the relevant table (this will be the first one in the list of tables)\n",
    "df = tables[0]\n",
    "\n",
    "# Step 5: Check the first few rows to understand the structure\n",
    "df.head()\n",
    "\n",
    "# Step 6: Clean the dataframe\n",
    "# Remove the columns that contain footnotes or unwanted symbols\n",
    "df.columns = df.columns.str.replace(r'\\[.*\\]', '', regex=True)  # Remove footnote references\n",
    "\n",
    "# Step 7: Save the DataFrame to the specified location\n",
    "file_path = r'F:\\MLpractrice\\blood\\blood_type_distribution.csv'  # Ensure this folder exists\n",
    "df.to_csv(file_path, index=False)\n",
    "\n",
    "# Step 8: Display the first few rows of the DataFrame for verification\n",
    "df.head()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "897cce3e-32b0-4e06-bd1a-6e340ce91230",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Total tables found: 3\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\AIC\\AppData\\Local\\Temp\\ipykernel_6096\\3339932350.py:20: FutureWarning: DataFrame.applymap has been deprecated. Use DataFrame.map instead.\n",
      "  df = df.applymap(str)\n"
     ]
    },
    {
     "ename": "AttributeError",
     "evalue": "Can only use .str accessor with string values!",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mAttributeError\u001b[0m                            Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[8], line 23\u001b[0m\n\u001b[0;32m     20\u001b[0m df \u001b[38;5;241m=\u001b[39m df\u001b[38;5;241m.\u001b[39mapplymap(\u001b[38;5;28mstr\u001b[39m)\n\u001b[0;32m     22\u001b[0m \u001b[38;5;66;03m# Remove the columns that contain footnotes or unwanted symbols\u001b[39;00m\n\u001b[1;32m---> 23\u001b[0m df\u001b[38;5;241m.\u001b[39mcolumns \u001b[38;5;241m=\u001b[39m df\u001b[38;5;241m.\u001b[39mcolumns\u001b[38;5;241m.\u001b[39mstr\u001b[38;5;241m.\u001b[39mreplace(\u001b[38;5;124mr\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124m\\\u001b[39m\u001b[38;5;124m[.*\u001b[39m\u001b[38;5;124m\\\u001b[39m\u001b[38;5;124m]\u001b[39m\u001b[38;5;124m'\u001b[39m, \u001b[38;5;124m'\u001b[39m\u001b[38;5;124m'\u001b[39m, regex\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mTrue\u001b[39;00m)  \u001b[38;5;66;03m# Remove footnote references\u001b[39;00m\n\u001b[0;32m     25\u001b[0m \u001b[38;5;66;03m# Step 7: Save the DataFrame to the specified location\u001b[39;00m\n\u001b[0;32m     26\u001b[0m file_path \u001b[38;5;241m=\u001b[39m \u001b[38;5;124mr\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mF:\u001b[39m\u001b[38;5;124m\\\u001b[39m\u001b[38;5;124mMLpractrice\u001b[39m\u001b[38;5;124m\\\u001b[39m\u001b[38;5;124mblood\u001b[39m\u001b[38;5;124m\\\u001b[39m\u001b[38;5;124mblood_type_distribution.csv\u001b[39m\u001b[38;5;124m'\u001b[39m  \u001b[38;5;66;03m# Ensure this folder exists\u001b[39;00m\n",
      "File \u001b[1;32mD:\\anapy\\Lib\\site-packages\\pandas\\core\\accessor.py:224\u001b[0m, in \u001b[0;36mCachedAccessor.__get__\u001b[1;34m(self, obj, cls)\u001b[0m\n\u001b[0;32m    221\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m obj \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[0;32m    222\u001b[0m     \u001b[38;5;66;03m# we're accessing the attribute of the class, i.e., Dataset.geo\u001b[39;00m\n\u001b[0;32m    223\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_accessor\n\u001b[1;32m--> 224\u001b[0m accessor_obj \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_accessor(obj)\n\u001b[0;32m    225\u001b[0m \u001b[38;5;66;03m# Replace the property with the accessor object. Inspired by:\u001b[39;00m\n\u001b[0;32m    226\u001b[0m \u001b[38;5;66;03m# https://www.pydanny.com/cached-property.html\u001b[39;00m\n\u001b[0;32m    227\u001b[0m \u001b[38;5;66;03m# We need to use object.__setattr__ because we overwrite __setattr__ on\u001b[39;00m\n\u001b[0;32m    228\u001b[0m \u001b[38;5;66;03m# NDFrame\u001b[39;00m\n\u001b[0;32m    229\u001b[0m \u001b[38;5;28mobject\u001b[39m\u001b[38;5;241m.\u001b[39m\u001b[38;5;21m__setattr__\u001b[39m(obj, \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_name, accessor_obj)\n",
      "File \u001b[1;32mD:\\anapy\\Lib\\site-packages\\pandas\\core\\strings\\accessor.py:191\u001b[0m, in \u001b[0;36mStringMethods.__init__\u001b[1;34m(self, data)\u001b[0m\n\u001b[0;32m    188\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21m__init__\u001b[39m(\u001b[38;5;28mself\u001b[39m, data) \u001b[38;5;241m-\u001b[39m\u001b[38;5;241m>\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[0;32m    189\u001b[0m     \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01mpandas\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mcore\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01marrays\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mstring_\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m StringDtype\n\u001b[1;32m--> 191\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_inferred_dtype \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_validate(data)\n\u001b[0;32m    192\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_is_categorical \u001b[38;5;241m=\u001b[39m \u001b[38;5;28misinstance\u001b[39m(data\u001b[38;5;241m.\u001b[39mdtype, CategoricalDtype)\n\u001b[0;32m    193\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_is_string \u001b[38;5;241m=\u001b[39m \u001b[38;5;28misinstance\u001b[39m(data\u001b[38;5;241m.\u001b[39mdtype, StringDtype)\n",
      "File \u001b[1;32mD:\\anapy\\Lib\\site-packages\\pandas\\core\\strings\\accessor.py:245\u001b[0m, in \u001b[0;36mStringMethods._validate\u001b[1;34m(data)\u001b[0m\n\u001b[0;32m    242\u001b[0m inferred_dtype \u001b[38;5;241m=\u001b[39m lib\u001b[38;5;241m.\u001b[39minfer_dtype(values, skipna\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mTrue\u001b[39;00m)\n\u001b[0;32m    244\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m inferred_dtype \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;129;01min\u001b[39;00m allowed_types:\n\u001b[1;32m--> 245\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mAttributeError\u001b[39;00m(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mCan only use .str accessor with string values!\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n\u001b[0;32m    246\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m inferred_dtype\n",
      "\u001b[1;31mAttributeError\u001b[0m: Can only use .str accessor with string values!"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "\n",
    "# Step 1: URL of the Wikipedia page\n",
    "url = 'https://en.wikipedia.org/wiki/Blood_type_distribution_by_country'\n",
    "\n",
    "# Step 2: Use pandas to directly read the table from the webpage\n",
    "tables = pd.read_html(url)\n",
    "\n",
    "# Step 3: Check how many tables are present\n",
    "print(f'Total tables found: {len(tables)}')\n",
    "\n",
    "# Step 4: Select the relevant table (this will be the first one in the list of tables)\n",
    "df = tables[0]\n",
    "\n",
    "# Step 5: Check the first few rows to understand the structure\n",
    "df.head()\n",
    "\n",
    "# Step 6: Clean the dataframe\n",
    "# Ensure all columns are of string type\n",
    "df = df.applymap(str)\n",
    "\n",
    "# Remove the columns that contain footnotes or unwanted symbols\n",
    "df.columns = df.columns.str.replace(r'\\[.*\\]', '', regex=True)  # Remove footnote references\n",
    "\n",
    "# Step 7: Save the DataFrame to the specified location\n",
    "file_path = r'F:\\MLpractrice\\blood\\blood_type_distribution.csv'  # Ensure this folder exists\n",
    "df.to_csv(file_path, index=False)\n",
    "\n",
    "# Step 8: Display the first few rows of the DataFrame for verification\n",
    "df.head()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "e8b9aafa-e4bb-4876-9992-d90558a9d2ac",
   "metadata": {},
   "outputs": [
    {
     "ename": "IndexError",
     "evalue": "list index out of range",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mIndexError\u001b[0m                                Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[9], line 44\u001b[0m\n\u001b[0;32m     42\u001b[0m a_m \u001b[38;5;241m=\u001b[39m cols[\u001b[38;5;241m7\u001b[39m]\u001b[38;5;241m.\u001b[39mget_text(strip\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mTrue\u001b[39;00m)\n\u001b[0;32m     43\u001b[0m b_m \u001b[38;5;241m=\u001b[39m cols[\u001b[38;5;241m8\u001b[39m]\u001b[38;5;241m.\u001b[39mget_text(strip\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mTrue\u001b[39;00m)\n\u001b[1;32m---> 44\u001b[0m ab_m \u001b[38;5;241m=\u001b[39m cols[\u001b[38;5;241m9\u001b[39m]\u001b[38;5;241m.\u001b[39mget_text(strip\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mTrue\u001b[39;00m)\n\u001b[0;32m     46\u001b[0m \u001b[38;5;66;03m# Append data to respective lists\u001b[39;00m\n\u001b[0;32m     47\u001b[0m countries\u001b[38;5;241m.\u001b[39mappend(country)\n",
      "\u001b[1;31mIndexError\u001b[0m: list index out of range"
     ]
    }
   ],
   "source": [
    "import requests\n",
    "import pandas as pd\n",
    "from bs4 import BeautifulSoup\n",
    "\n",
    "# URL of the Wikipedia page with the blood type distribution table\n",
    "url = \"https://en.wikipedia.org/wiki/Blood_type_distribution_by_country\"\n",
    "\n",
    "# Send a GET request to the URL\n",
    "response = requests.get(url)\n",
    "\n",
    "# Parse the page content using BeautifulSoup\n",
    "soup = BeautifulSoup(response.content, \"html.parser\")\n",
    "\n",
    "# Find the table containing the blood type distribution\n",
    "table = soup.find(\"table\", {\"class\": \"wikitable\"})\n",
    "\n",
    "# Initialize lists to store the extracted data\n",
    "countries = []\n",
    "populations = []\n",
    "o_plus = []\n",
    "a_plus = []\n",
    "b_plus = []\n",
    "ab_plus = []\n",
    "o_minus = []\n",
    "a_minus = []\n",
    "b_minus = []\n",
    "ab_minus = []\n",
    "\n",
    "# Iterate through each row of the table (excluding the header)\n",
    "for row in table.find_all(\"tr\")[1:]:\n",
    "    cols = row.find_all(\"td\")\n",
    "    \n",
    "    # Make sure there are enough columns in the row\n",
    "    if len(cols) >= 9:\n",
    "        country = cols[0].get_text(strip=True)\n",
    "        population = cols[1].get_text(strip=True)\n",
    "        o_p = cols[2].get_text(strip=True)\n",
    "        a_p = cols[3].get_text(strip=True)\n",
    "        b_p = cols[4].get_text(strip=True)\n",
    "        ab_p = cols[5].get_text(strip=True)\n",
    "        o_m = cols[6].get_text(strip=True)\n",
    "        a_m = cols[7].get_text(strip=True)\n",
    "        b_m = cols[8].get_text(strip=True)\n",
    "        ab_m = cols[9].get_text(strip=True)\n",
    "        \n",
    "        # Append data to respective lists\n",
    "        countries.append(country)\n",
    "        populations.append(population)\n",
    "        o_plus.append(o_p)\n",
    "        a_plus.append(a_p)\n",
    "        b_plus.append(b_p)\n",
    "        ab_plus.append(ab_p)\n",
    "        o_minus.append(o_m)\n",
    "        a_minus.append(a_m)\n",
    "        b_minus.append(b_m)\n",
    "        ab_minus.append(ab_m)\n",
    "\n",
    "# Create a DataFrame using pandas\n",
    "df = pd.DataFrame({\n",
    "    \"Country/Dependency\": countries,\n",
    "    \"Population\": populations,\n",
    "    \"O+\": o_plus,\n",
    "    \"A+\": a_plus,\n",
    "    \"B+\": b_plus,\n",
    "    \"AB+\": ab_plus,\n",
    "    \"O-\": o_minus,\n",
    "    \"A-\": a_minus,\n",
    "    \"B-\": b_minus,\n",
    "    \"AB-\": ab_minus\n",
    "})\n",
    "\n",
    "# Save the DataFrame to a CSV file\n",
    "df.to_csv(\"blood_type_distribution_by_country.csv\", index=False)\n",
    "\n",
    "print(\"CSV file has been created and saved as 'blood_type_distribution_by_country.csv'\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "f6433434-59a4-437a-a2d2-0dff42fa44d6",
   "metadata": {},
   "outputs": [
    {
     "ename": "IndexError",
     "evalue": "list index out of range",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mIndexError\u001b[0m                                Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[10], line 44\u001b[0m\n\u001b[0;32m     42\u001b[0m a_m \u001b[38;5;241m=\u001b[39m cols[\u001b[38;5;241m7\u001b[39m]\u001b[38;5;241m.\u001b[39mget_text(strip\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mTrue\u001b[39;00m)\n\u001b[0;32m     43\u001b[0m b_m \u001b[38;5;241m=\u001b[39m cols[\u001b[38;5;241m8\u001b[39m]\u001b[38;5;241m.\u001b[39mget_text(strip\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mTrue\u001b[39;00m)\n\u001b[1;32m---> 44\u001b[0m ab_m \u001b[38;5;241m=\u001b[39m cols[\u001b[38;5;241m9\u001b[39m]\u001b[38;5;241m.\u001b[39mget_text(strip\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mTrue\u001b[39;00m)\n\u001b[0;32m     46\u001b[0m \u001b[38;5;66;03m# Append data to respective lists\u001b[39;00m\n\u001b[0;32m     47\u001b[0m countries\u001b[38;5;241m.\u001b[39mappend(country)\n",
      "\u001b[1;31mIndexError\u001b[0m: list index out of range"
     ]
    }
   ],
   "source": [
    "import requests\n",
    "import pandas as pd\n",
    "from bs4 import BeautifulSoup\n",
    "\n",
    "# URL of the Wikipedia page with the blood type distribution table\n",
    "url = \"https://en.wikipedia.org/wiki/Blood_type_distribution_by_country\"\n",
    "\n",
    "# Send a GET request to the URL\n",
    "response = requests.get(url)\n",
    "\n",
    "# Parse the page content using BeautifulSoup\n",
    "soup = BeautifulSoup(response.content, \"html.parser\")\n",
    "\n",
    "# Find the table containing the blood type distribution\n",
    "table = soup.find(\"table\", {\"class\": \"wikitable\"})\n",
    "\n",
    "# Initialize lists to store the extracted data\n",
    "countries = []\n",
    "populations = []\n",
    "o_plus = []\n",
    "a_plus = []\n",
    "b_plus = []\n",
    "ab_plus = []\n",
    "o_minus = []\n",
    "a_minus = []\n",
    "b_minus = []\n",
    "ab_minus = []\n",
    "\n",
    "# Iterate through each row of the table (excluding the header)\n",
    "for row in table.find_all(\"tr\")[1:]:\n",
    "    cols = row.find_all(\"td\")\n",
    "    \n",
    "    # Only process rows that have enough columns (at least 9 columns for full data)\n",
    "    if len(cols) >= 9:\n",
    "        country = cols[0].get_text(strip=True)\n",
    "        population = cols[1].get_text(strip=True)\n",
    "        o_p = cols[2].get_text(strip=True)\n",
    "        a_p = cols[3].get_text(strip=True)\n",
    "        b_p = cols[4].get_text(strip=True)\n",
    "        ab_p = cols[5].get_text(strip=True)\n",
    "        o_m = cols[6].get_text(strip=True)\n",
    "        a_m = cols[7].get_text(strip=True)\n",
    "        b_m = cols[8].get_text(strip=True)\n",
    "        ab_m = cols[9].get_text(strip=True)\n",
    "        \n",
    "        # Append data to respective lists\n",
    "        countries.append(country)\n",
    "        populations.append(population)\n",
    "        o_plus.append(o_p)\n",
    "        a_plus.append(a_p)\n",
    "        b_plus.append(b_p)\n",
    "        ab_plus.append(ab_p)\n",
    "        o_minus.append(o_m)\n",
    "        a_minus.append(a_m)\n",
    "        b_minus.append(b_m)\n",
    "        ab_minus.append(ab_m)\n",
    "    else:\n",
    "        # If a row doesn't have enough columns, we can skip it or handle it differently\n",
    "        print(f\"Skipping row with insufficient data: {row}\")\n",
    "\n",
    "# Create a DataFrame using pandas\n",
    "df = pd.DataFrame({\n",
    "    \"Country/Dependency\": countries,\n",
    "    \"Population\": populations,\n",
    "    \"O+\": o_plus,\n",
    "    \"A+\": a_plus,\n",
    "    \"B+\": b_plus,\n",
    "    \"AB+\": ab_plus,\n",
    "    \"O-\": o_minus,\n",
    "    \"A-\": a_minus,\n",
    "    \"B-\": b_minus,\n",
    "    \"AB-\": ab_minus\n",
    "})\n",
    "\n",
    "# Save the DataFrame to a CSV file\n",
    "df.to_csv(\"blood_type_distribution_by_country.csv\", index=False)\n",
    "\n",
    "print(\"CSV file has been created and saved as 'blood_type_distribution_by_country.csv'\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "1e0acebe-3f4d-42a1-9bf8-4bce5c8a1052",
   "metadata": {},
   "outputs": [
    {
     "ename": "IndexError",
     "evalue": "list index out of range",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mIndexError\u001b[0m                                Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[11], line 47\u001b[0m\n\u001b[0;32m     45\u001b[0m     a_m \u001b[38;5;241m=\u001b[39m cols[\u001b[38;5;241m7\u001b[39m]\u001b[38;5;241m.\u001b[39mget_text(strip\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mTrue\u001b[39;00m)\n\u001b[0;32m     46\u001b[0m     b_m \u001b[38;5;241m=\u001b[39m cols[\u001b[38;5;241m8\u001b[39m]\u001b[38;5;241m.\u001b[39mget_text(strip\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mTrue\u001b[39;00m)\n\u001b[1;32m---> 47\u001b[0m     ab_m \u001b[38;5;241m=\u001b[39m cols[\u001b[38;5;241m9\u001b[39m]\u001b[38;5;241m.\u001b[39mget_text(strip\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mTrue\u001b[39;00m)\n\u001b[0;32m     49\u001b[0m \u001b[38;5;66;03m# If there are fewer columns, we'll try to extract what is available\u001b[39;00m\n\u001b[0;32m     50\u001b[0m \u001b[38;5;28;01melif\u001b[39;00m \u001b[38;5;28mlen\u001b[39m(cols) \u001b[38;5;241m>\u001b[39m\u001b[38;5;241m=\u001b[39m \u001b[38;5;241m8\u001b[39m:\n",
      "\u001b[1;31mIndexError\u001b[0m: list index out of range"
     ]
    }
   ],
   "source": [
    "import requests\n",
    "import pandas as pd\n",
    "from bs4 import BeautifulSoup\n",
    "\n",
    "# URL of the Wikipedia page with the blood type distribution table\n",
    "url = \"https://en.wikipedia.org/wiki/Blood_type_distribution_by_country\"\n",
    "\n",
    "# Send a GET request to the URL\n",
    "response = requests.get(url)\n",
    "\n",
    "# Parse the page content using BeautifulSoup\n",
    "soup = BeautifulSoup(response.content, \"html.parser\")\n",
    "\n",
    "# Find the table containing the blood type distribution\n",
    "table = soup.find(\"table\", {\"class\": \"wikitable\"})\n",
    "\n",
    "# Initialize lists to store the extracted data\n",
    "countries = []\n",
    "populations = []\n",
    "o_plus = []\n",
    "a_plus = []\n",
    "b_plus = []\n",
    "ab_plus = []\n",
    "o_minus = []\n",
    "a_minus = []\n",
    "b_minus = []\n",
    "ab_minus = []\n",
    "\n",
    "# Iterate through each row of the table (excluding the header)\n",
    "for row in table.find_all(\"tr\")[1:]:\n",
    "    cols = row.find_all(\"td\")\n",
    "    \n",
    "    # Initialize data as empty string or None if data is missing\n",
    "    country = population = o_p = a_p = b_p = ab_p = o_m = a_m = b_m = ab_m = None\n",
    "    \n",
    "    # Only process rows that have enough columns (at least 9 columns for full data)\n",
    "    if len(cols) >= 9:\n",
    "        country = cols[0].get_text(strip=True)\n",
    "        population = cols[1].get_text(strip=True)\n",
    "        o_p = cols[2].get_text(strip=True)\n",
    "        a_p = cols[3].get_text(strip=True)\n",
    "        b_p = cols[4].get_text(strip=True)\n",
    "        ab_p = cols[5].get_text(strip=True)\n",
    "        o_m = cols[6].get_text(strip=True)\n",
    "        a_m = cols[7].get_text(strip=True)\n",
    "        b_m = cols[8].get_text(strip=True)\n",
    "        ab_m = cols[9].get_text(strip=True)\n",
    "    \n",
    "    # If there are fewer columns, we'll try to extract what is available\n",
    "    elif len(cols) >= 8:\n",
    "        country = cols[0].get_text(strip=True)\n",
    "        population = cols[1].get_text(strip=True)\n",
    "        o_p = cols[2].get_text(strip=True)\n",
    "        a_p = cols[3].get_text(strip=True)\n",
    "        b_p = cols[4].get_text(strip=True)\n",
    "        ab_p = cols[5].get_text(strip=True)\n",
    "        o_m = cols[6].get_text(strip=True)\n",
    "        a_m = cols[7].get_text(strip=True)\n",
    "    \n",
    "    elif len(cols) >= 7:\n",
    "        country = cols[0].get_text(strip=True)\n",
    "        population = cols[1].get_text(strip=True)\n",
    "        o_p = cols[2].get_text(strip=True)\n",
    "        a_p = cols[3].get_text(strip=True)\n",
    "        b_p = cols[4].get_text(strip=True)\n",
    "        ab_p = cols[5].get_text(strip=True)\n",
    "    \n",
    "    elif len(cols) >= 6:\n",
    "        country = cols[0].get_text(strip=True)\n",
    "        population = cols[1].get_text(strip=True)\n",
    "        o_p = cols[2].get_text(strip=True)\n",
    "        a_p = cols[3].get_text(strip=True)\n",
    "        b_p = cols[4].get_text(strip=True)\n",
    "    \n",
    "    # Append data to respective lists\n",
    "    countries.append(country)\n",
    "    populations.append(population)\n",
    "    o_plus.append(o_p)\n",
    "    a_plus.append(a_p)\n",
    "    b_plus.append(b_p)\n",
    "    ab_plus.append(ab_p)\n",
    "    o_minus.append(o_m)\n",
    "    a_minus.append(a_m)\n",
    "    b_minus.append(b_m)\n",
    "    ab_minus.append(ab_m)\n",
    "\n",
    "# Create a DataFrame using pandas\n",
    "df = pd.DataFrame({\n",
    "    \"Country/Dependency\": countries,\n",
    "    \"Population\": populations,\n",
    "    \"O+\": o_plus,\n",
    "    \"A+\": a_plus,\n",
    "    \"B+\": b_plus,\n",
    "    \"AB+\": ab_plus,\n",
    "    \"O-\": o_minus,\n",
    "    \"A-\": a_minus,\n",
    "    \"B-\": b_minus,\n",
    "    \"AB-\": ab_minus\n",
    "})\n",
    "\n",
    "# Save the DataFrame to a CSV file\n",
    "df.to_csv(\"blood_type_distribution_by_country.csv\", index=False)\n",
    "\n",
    "print(\"CSV file has been created and saved as 'blood_type_distribution_by_country.csv'\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "23d4c195-a2eb-49fd-bd6b-bae7faf6009e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CSV file has been created and saved as 'blood_type_distribution_by_country.csv'\n"
     ]
    }
   ],
   "source": [
    "import requests\n",
    "import pandas as pd\n",
    "from bs4 import BeautifulSoup\n",
    "\n",
    "# URL of the Wikipedia page with the blood type distribution table\n",
    "url = \"https://en.wikipedia.org/wiki/Blood_type_distribution_by_country\"\n",
    "\n",
    "# Send a GET request to the URL\n",
    "response = requests.get(url)\n",
    "\n",
    "# Parse the page content using BeautifulSoup\n",
    "soup = BeautifulSoup(response.content, \"html.parser\")\n",
    "\n",
    "# Find the table containing the blood type distribution\n",
    "table = soup.find(\"table\", {\"class\": \"wikitable\"})\n",
    "\n",
    "# Initialize lists to store the extracted data\n",
    "countries = []\n",
    "populations = []\n",
    "o_plus = []\n",
    "a_plus = []\n",
    "b_plus = []\n",
    "ab_plus = []\n",
    "o_minus = []\n",
    "a_minus = []\n",
    "b_minus = []\n",
    "ab_minus = []\n",
    "\n",
    "# Iterate through each row of the table (excluding the header)\n",
    "for row in table.find_all(\"tr\")[1:]:\n",
    "    cols = row.find_all(\"td\")\n",
    "    \n",
    "    # Initialize data as empty string or None if data is missing\n",
    "    country = population = o_p = a_p = b_p = ab_p = o_m = a_m = b_m = ab_m = None\n",
    "    \n",
    "    # Check if the row has enough columns\n",
    "    if len(cols) > 0:\n",
    "        country = cols[0].get_text(strip=True) if len(cols) > 0 else None\n",
    "    if len(cols) > 1:\n",
    "        population = cols[1].get_text(strip=True) if len(cols) > 1 else None\n",
    "    if len(cols) > 2:\n",
    "        o_p = cols[2].get_text(strip=True) if len(cols) > 2 else None\n",
    "    if len(cols) > 3:\n",
    "        a_p = cols[3].get_text(strip=True) if len(cols) > 3 else None\n",
    "    if len(cols) > 4:\n",
    "        b_p = cols[4].get_text(strip=True) if len(cols) > 4 else None\n",
    "    if len(cols) > 5:\n",
    "        ab_p = cols[5].get_text(strip=True) if len(cols) > 5 else None\n",
    "    if len(cols) > 6:\n",
    "        o_m = cols[6].get_text(strip=True) if len(cols) > 6 else None\n",
    "    if len(cols) > 7:\n",
    "        a_m = cols[7].get_text(strip=True) if len(cols) > 7 else None\n",
    "    if len(cols) > 8:\n",
    "        b_m = cols[8].get_text(strip=True) if len(cols) > 8 else None\n",
    "    if len(cols) > 9:\n",
    "        ab_m = cols[9].get_text(strip=True) if len(cols) > 9 else None\n",
    "    \n",
    "    # Append data to respective lists\n",
    "    countries.append(country)\n",
    "    populations.append(population)\n",
    "    o_plus.append(o_p)\n",
    "    a_plus.append(a_p)\n",
    "    b_plus.append(b_p)\n",
    "    ab_plus.append(ab_p)\n",
    "    o_minus.append(o_m)\n",
    "    a_minus.append(a_m)\n",
    "    b_minus.append(b_m)\n",
    "    ab_minus.append(ab_m)\n",
    "\n",
    "# Create a DataFrame using pandas\n",
    "df = pd.DataFrame({\n",
    "    \"Country/Dependency\": countries,\n",
    "    \"Population\": populations,\n",
    "    \"O+\": o_plus,\n",
    "    \"A+\": a_plus,\n",
    "    \"B+\": b_plus,\n",
    "    \"AB+\": ab_plus,\n",
    "    \"O-\": o_minus,\n",
    "    \"A-\": a_minus,\n",
    "    \"B-\": b_minus,\n",
    "    \"AB-\": ab_minus\n",
    "})\n",
    "\n",
    "# Save the DataFrame to a CSV file\n",
    "df.to_csv(\"F:/MLpractrice/blood/blood_type_distribution_by_country.csv\", index=False)\n",
    "\n",
    "print(\"CSV file has been created and saved as 'blood_type_distribution_by_country.csv'\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "3bfa1e0d-cb1c-4622-8983-a9b02fe20c3a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CSV file has been created and saved as 'blood_type_distribution_by_country.csv'\n"
     ]
    }
   ],
   "source": [
    "import requests\n",
    "import pandas as pd\n",
    "from bs4 import BeautifulSoup\n",
    "\n",
    "# URL of the Wikipedia page with the blood type distribution table\n",
    "url = \"https://en.wikipedia.org/wiki/Blood_type_distribution_by_country\"\n",
    "\n",
    "# Send a GET request to the URL\n",
    "response = requests.get(url)\n",
    "\n",
    "# Parse the page content using BeautifulSoup\n",
    "soup = BeautifulSoup(response.content, \"html.parser\")\n",
    "\n",
    "# Find the table containing the blood type distribution\n",
    "table = soup.find(\"table\", {\"class\": \"wikitable\"})\n",
    "\n",
    "# Initialize lists to store the extracted data\n",
    "countries = []\n",
    "populations = []\n",
    "o_plus = []\n",
    "a_plus = []\n",
    "b_plus = []\n",
    "ab_plus = []\n",
    "o_minus = []\n",
    "a_minus = []\n",
    "b_minus = []\n",
    "ab_minus = []\n",
    "\n",
    "# Iterate through each row of the table (excluding the header)\n",
    "for row in table.find_all(\"tr\")[1:]:\n",
    "    cols = row.find_all(\"td\")\n",
    "    \n",
    "    # Initialize data as empty string or None if data is missing\n",
    "    country = population = o_p = a_p = b_p = ab_p = o_m = a_m = b_m = ab_m = None\n",
    "    \n",
    "    # Check if the row has enough columns\n",
    "    if len(cols) > 0:\n",
    "        # Country name might be inside an <a> tag\n",
    "        country_tag = cols[0].find(\"a\")\n",
    "        country = country_tag.get_text(strip=True) if country_tag else cols[0].get_text(strip=True)\n",
    "\n",
    "    if len(cols) > 1:\n",
    "        population = cols[1].get_text(strip=True) if len(cols) > 1 else None\n",
    "    if len(cols) > 2:\n",
    "        o_p = cols[2].get_text(strip=True) if len(cols) > 2 else None\n",
    "    if len(cols) > 3:\n",
    "        a_p = cols[3].get_text(strip=True) if len(cols) > 3 else None\n",
    "    if len(cols) > 4:\n",
    "        b_p = cols[4].get_text(strip=True) if len(cols) > 4 else None\n",
    "    if len(cols) > 5:\n",
    "        ab_p = cols[5].get_text(strip=True) if len(cols) > 5 else None\n",
    "    if len(cols) > 6:\n",
    "        o_m = cols[6].get_text(strip=True) if len(cols) > 6 else None\n",
    "    if len(cols) > 7:\n",
    "        a_m = cols[7].get_text(strip=True) if len(cols) > 7 else None\n",
    "    if len(cols) > 8:\n",
    "        b_m = cols[8].get_text(strip=True) if len(cols) > 8 else None\n",
    "    if len(cols) > 9:\n",
    "        ab_m = cols[9].get_text(strip=True) if len(cols) > 9 else None\n",
    "    \n",
    "    # Append data to respective lists\n",
    "    countries.append(country)\n",
    "    populations.append(population)\n",
    "    o_plus.append(o_p)\n",
    "    a_plus.append(a_p)\n",
    "    b_plus.append(b_p)\n",
    "    ab_plus.append(ab_p)\n",
    "    o_minus.append(o_m)\n",
    "    a_minus.append(a_m)\n",
    "    b_minus.append(b_m)\n",
    "    ab_minus.append(ab_m)\n",
    "\n",
    "# Create a DataFrame using pandas\n",
    "df = pd.DataFrame({\n",
    "    \"Country/Dependency\": countries,\n",
    "    \"Population\": populations,\n",
    "    \"O+\": o_plus,\n",
    "    \"A+\": a_plus,\n",
    "    \"B+\": b_plus,\n",
    "    \"AB+\": ab_plus,\n",
    "    \"O-\": o_minus,\n",
    "    \"A-\": a_minus,\n",
    "    \"B-\": b_minus,\n",
    "    \"AB-\": ab_minus\n",
    "})\n",
    "\n",
    "# Save the DataFrame to a CSV file\n",
    "df.to_csv(\"F:/MLpractrice/blood/blood_type_distribution_by_country2.csv\", index=False)\n",
    "\n",
    "print(\"CSV file has been created and saved as 'blood_type_distribution_by_country.csv'\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "666b4267-bb5d-432f-bcad-52181c369b58",
   "metadata": {},
   "outputs": [
    {
     "ename": "UnicodeDecodeError",
     "evalue": "'utf-8' codec can't decode byte 0xa0 in position 57: invalid start byte",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mUnicodeDecodeError\u001b[0m                        Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[16], line 7\u001b[0m\n\u001b[0;32m      4\u001b[0m csv_file_path \u001b[38;5;241m=\u001b[39m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mF:/MLpractrice/blood/blood_type_distribution_by_country.csv\u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[0;32m      6\u001b[0m \u001b[38;5;66;03m# Read the CSV file into a pandas DataFrame\u001b[39;00m\n\u001b[1;32m----> 7\u001b[0m df \u001b[38;5;241m=\u001b[39m pd\u001b[38;5;241m.\u001b[39mread_csv(csv_file_path)\n\u001b[0;32m      9\u001b[0m \u001b[38;5;66;03m# Display the first 5 rows (head) of the DataFrame\u001b[39;00m\n\u001b[0;32m     10\u001b[0m \u001b[38;5;28mprint\u001b[39m(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mHead of the DataFrame:\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n",
      "File \u001b[1;32mD:\\anapy\\Lib\\site-packages\\pandas\\io\\parsers\\readers.py:1026\u001b[0m, in \u001b[0;36mread_csv\u001b[1;34m(filepath_or_buffer, sep, delimiter, header, names, index_col, usecols, dtype, engine, converters, true_values, false_values, skipinitialspace, skiprows, skipfooter, nrows, na_values, keep_default_na, na_filter, verbose, skip_blank_lines, parse_dates, infer_datetime_format, keep_date_col, date_parser, date_format, dayfirst, cache_dates, iterator, chunksize, compression, thousands, decimal, lineterminator, quotechar, quoting, doublequote, escapechar, comment, encoding, encoding_errors, dialect, on_bad_lines, delim_whitespace, low_memory, memory_map, float_precision, storage_options, dtype_backend)\u001b[0m\n\u001b[0;32m   1013\u001b[0m kwds_defaults \u001b[38;5;241m=\u001b[39m _refine_defaults_read(\n\u001b[0;32m   1014\u001b[0m     dialect,\n\u001b[0;32m   1015\u001b[0m     delimiter,\n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m   1022\u001b[0m     dtype_backend\u001b[38;5;241m=\u001b[39mdtype_backend,\n\u001b[0;32m   1023\u001b[0m )\n\u001b[0;32m   1024\u001b[0m kwds\u001b[38;5;241m.\u001b[39mupdate(kwds_defaults)\n\u001b[1;32m-> 1026\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m _read(filepath_or_buffer, kwds)\n",
      "File \u001b[1;32mD:\\anapy\\Lib\\site-packages\\pandas\\io\\parsers\\readers.py:620\u001b[0m, in \u001b[0;36m_read\u001b[1;34m(filepath_or_buffer, kwds)\u001b[0m\n\u001b[0;32m    617\u001b[0m _validate_names(kwds\u001b[38;5;241m.\u001b[39mget(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mnames\u001b[39m\u001b[38;5;124m\"\u001b[39m, \u001b[38;5;28;01mNone\u001b[39;00m))\n\u001b[0;32m    619\u001b[0m \u001b[38;5;66;03m# Create the parser.\u001b[39;00m\n\u001b[1;32m--> 620\u001b[0m parser \u001b[38;5;241m=\u001b[39m TextFileReader(filepath_or_buffer, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwds)\n\u001b[0;32m    622\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m chunksize \u001b[38;5;129;01mor\u001b[39;00m iterator:\n\u001b[0;32m    623\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m parser\n",
      "File \u001b[1;32mD:\\anapy\\Lib\\site-packages\\pandas\\io\\parsers\\readers.py:1620\u001b[0m, in \u001b[0;36mTextFileReader.__init__\u001b[1;34m(self, f, engine, **kwds)\u001b[0m\n\u001b[0;32m   1617\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39moptions[\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mhas_index_names\u001b[39m\u001b[38;5;124m\"\u001b[39m] \u001b[38;5;241m=\u001b[39m kwds[\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mhas_index_names\u001b[39m\u001b[38;5;124m\"\u001b[39m]\n\u001b[0;32m   1619\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mhandles: IOHandles \u001b[38;5;241m|\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[1;32m-> 1620\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_engine \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_make_engine(f, \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mengine)\n",
      "File \u001b[1;32mD:\\anapy\\Lib\\site-packages\\pandas\\io\\parsers\\readers.py:1898\u001b[0m, in \u001b[0;36mTextFileReader._make_engine\u001b[1;34m(self, f, engine)\u001b[0m\n\u001b[0;32m   1895\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mValueError\u001b[39;00m(msg)\n\u001b[0;32m   1897\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[1;32m-> 1898\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m mapping[engine](f, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39m\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39moptions)\n\u001b[0;32m   1899\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m \u001b[38;5;167;01mException\u001b[39;00m:\n\u001b[0;32m   1900\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mhandles \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n",
      "File \u001b[1;32mD:\\anapy\\Lib\\site-packages\\pandas\\io\\parsers\\c_parser_wrapper.py:93\u001b[0m, in \u001b[0;36mCParserWrapper.__init__\u001b[1;34m(self, src, **kwds)\u001b[0m\n\u001b[0;32m     90\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m kwds[\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mdtype_backend\u001b[39m\u001b[38;5;124m\"\u001b[39m] \u001b[38;5;241m==\u001b[39m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mpyarrow\u001b[39m\u001b[38;5;124m\"\u001b[39m:\n\u001b[0;32m     91\u001b[0m     \u001b[38;5;66;03m# Fail here loudly instead of in cython after reading\u001b[39;00m\n\u001b[0;32m     92\u001b[0m     import_optional_dependency(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mpyarrow\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n\u001b[1;32m---> 93\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_reader \u001b[38;5;241m=\u001b[39m parsers\u001b[38;5;241m.\u001b[39mTextReader(src, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwds)\n\u001b[0;32m     95\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39munnamed_cols \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_reader\u001b[38;5;241m.\u001b[39munnamed_cols\n\u001b[0;32m     97\u001b[0m \u001b[38;5;66;03m# error: Cannot determine type of 'names'\u001b[39;00m\n",
      "File \u001b[1;32mparsers.pyx:574\u001b[0m, in \u001b[0;36mpandas._libs.parsers.TextReader.__cinit__\u001b[1;34m()\u001b[0m\n",
      "File \u001b[1;32mparsers.pyx:663\u001b[0m, in \u001b[0;36mpandas._libs.parsers.TextReader._get_header\u001b[1;34m()\u001b[0m\n",
      "File \u001b[1;32mparsers.pyx:874\u001b[0m, in \u001b[0;36mpandas._libs.parsers.TextReader._tokenize_rows\u001b[1;34m()\u001b[0m\n",
      "File \u001b[1;32mparsers.pyx:891\u001b[0m, in \u001b[0;36mpandas._libs.parsers.TextReader._check_tokenize_status\u001b[1;34m()\u001b[0m\n",
      "File \u001b[1;32mparsers.pyx:2053\u001b[0m, in \u001b[0;36mpandas._libs.parsers.raise_parser_error\u001b[1;34m()\u001b[0m\n",
      "\u001b[1;31mUnicodeDecodeError\u001b[0m: 'utf-8' codec can't decode byte 0xa0 in position 57: invalid start byte"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "\n",
    "# Path to the CSV file\n",
    "csv_file_path = \"F:/MLpractrice/blood/blood_type_distribution_by_country.csv\"\n",
    "\n",
    "# Read the CSV file into a pandas DataFrame\n",
    "df = pd.read_csv(csv_file_path)\n",
    "\n",
    "# Display the first 5 rows (head) of the DataFrame\n",
    "print(\"Head of the DataFrame:\")\n",
    "print(df.head())\n",
    "\n",
    "# Display the first 10 values (rows)\n",
    "print(\"\\nFirst 10 rows of the DataFrame:\")\n",
    "print(df.head(10))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "21f9de9d-0c74-45c3-aada-7fe5a52c92b8",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Head of the DataFrame:\n",
      "  Country/Dependency  Population      O+      A+      B+    AB+     O-     A-  \\\n",
      "0         Albania[2]   3,074,579  34.10%  31.20%  14.50%  5.20%  6.00%  5.50%   \n",
      "1         Algeria[3]  43,576,691  40.00%  30.00%  15.00%  4.25%  6.60%  2.30%   \n",
      "2       Argentina[4]  45,479,118  50.34%  31.09%   8.20%  2.16%  4.29%  2.98%   \n",
      "3         Armenia[5]   3,021,324  29.00%  46.30%  12.00%  5.60%  2.00%  3.70%   \n",
      "4       Australia[6]  25,466,459  38.00%  32.00%  12.00%  4.00%  7.00%  6.00%   \n",
      "\n",
      "      B-    AB-  \n",
      "0  2.60%  0.90%  \n",
      "1  1.10%  0.75%  \n",
      "2  0.74%  0.20%  \n",
      "3  1.00%  0.40%  \n",
      "4  2.00%  1.00%  \n",
      "\n",
      "First 10 rows of the DataFrame:\n",
      "  Country/Dependency   Population      O+      A+      B+    AB+     O-  \\\n",
      "0         Albania[2]    3,074,579  34.10%  31.20%  14.50%  5.20%  6.00%   \n",
      "1         Algeria[3]   43,576,691  40.00%  30.00%  15.00%  4.25%  6.60%   \n",
      "2       Argentina[4]   45,479,118  50.34%  31.09%   8.20%  2.16%  4.29%   \n",
      "3         Armenia[5]    3,021,324  29.00%  46.30%  12.00%  5.60%  2.00%   \n",
      "4       Australia[6]   25,466,459  38.00%  32.00%  12.00%  4.00%  7.00%   \n",
      "5         Austria[7]    8,859,449  30.00%  37.00%  12.00%  5.00%  6.00%   \n",
      "6         Azerbaijan   10,205,810  29.80%  30.00%  21.10%  9.00%  3.30%   \n",
      "7            Bahrain    1,505,003  48.48%  15.35%  22.61%  3.67%  3.27%   \n",
      "8      Bangladesh[8]  164,098,818  29.21%  26.30%  33.12%  9.59%  0.53%   \n",
      "9            Belarus    9,441,842  32.30%  30.60%  15.30%  6.80%  5.70%   \n",
      "\n",
      "      A-     B-    AB-  \n",
      "0  5.50%  2.60%  0.90%  \n",
      "1  2.30%  1.10%  0.75%  \n",
      "2  2.98%  0.74%  0.20%  \n",
      "3  3.70%  1.00%  0.40%  \n",
      "4  6.00%  2.00%  1.00%  \n",
      "5  7.00%  2.00%  0.45%  \n",
      "6  3.40%  2.40%  1.00%  \n",
      "7  1.33%  1.04%  0.25%  \n",
      "8  0.48%  0.60%  0.17%  \n",
      "9  5.40%  2.70%  1.20%  \n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "\n",
    "# Path to the CSV file\n",
    "csv_file_path = \"F:/MLpractrice/blood/blood_type_distribution_by_country.csv\"\n",
    "\n",
    "# Try reading the CSV file with a different encoding (ISO-8859-1 or cp1252)\n",
    "df = pd.read_csv(csv_file_path, encoding='ISO-8859-1')\n",
    "\n",
    "# Display the first 5 rows (head) of the DataFrame\n",
    "print(\"Head of the DataFrame:\")\n",
    "print(df.head())\n",
    "\n",
    "# Display the first 10 rows of the DataFrame\n",
    "print(\"\\nFirst 10 rows of the DataFrame:\")\n",
    "print(df.head(10))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "5c2cb898-5121-479b-9115-c31612788048",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Head of the cleaned DataFrame:\n",
      "  Country/Dependency  Population      O+      A+      B+    AB+     O-     A-  \\\n",
      "0            Albania   3,074,579  34.10%  31.20%  14.50%  5.20%  6.00%  5.50%   \n",
      "1            Algeria  43,576,691  40.00%  30.00%  15.00%  4.25%  6.60%  2.30%   \n",
      "2          Argentina  45,479,118  50.34%  31.09%   8.20%  2.16%  4.29%  2.98%   \n",
      "3            Armenia   3,021,324  29.00%  46.30%  12.00%  5.60%  2.00%  3.70%   \n",
      "4          Australia  25,466,459  38.00%  32.00%  12.00%  4.00%  7.00%  6.00%   \n",
      "\n",
      "      B-    AB-  \n",
      "0  2.60%  0.90%  \n",
      "1  1.10%  0.75%  \n",
      "2  0.74%  0.20%  \n",
      "3  1.00%  0.40%  \n",
      "4  2.00%  1.00%  \n",
      "\n",
      "Cleaned data saved to: F:/MLpractrice/blood/cleaned_blood_type_distribution_by_country.csv\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import re\n",
    "\n",
    "# Path to the CSV file\n",
    "csv_file_path = \"F:/MLpractrice/blood/blood_type_distribution_by_country.csv\"\n",
    "\n",
    "# Read the CSV file with appropriate encoding\n",
    "df = pd.read_csv(csv_file_path, encoding='ISO-8859-1')\n",
    "\n",
    "# Clean the \"Country/Dependency\" column by removing the \"[number]\" part\n",
    "df['Country/Dependency'] = df['Country/Dependency'].apply(lambda x: re.sub(r'\\[\\d+\\]', '', x).strip())\n",
    "\n",
    "# Display the cleaned DataFrame head\n",
    "print(\"Head of the cleaned DataFrame:\")\n",
    "print(df.head())\n",
    "\n",
    "# Optionally, save the cleaned DataFrame back to a new CSV file\n",
    "output_csv_file = \"F:/MLpractrice/blood/cleaned_blood_type_distribution_by_country.csv\"\n",
    "df.to_csv(output_csv_file, index=False)\n",
    "\n",
    "print(f\"\\nCleaned data saved to: {output_csv_file}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "d9c13c9e-e2b8-4706-836c-9ecc6817da1a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Countries with missing blood group values:\n",
      "   Country/Dependency\n",
      "31              Egypt\n",
      "75           Mongolia\n",
      "\n",
      "The countries with missing values have been saved to: F:/MLpractrice/blood/countries_with_missing_blood_group_values.csv\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "\n",
    "# Path to the cleaned CSV file\n",
    "csv_file_path = \"F:/MLpractrice/blood/cleaned_blood_type_distribution_by_country.csv\"\n",
    "\n",
    "# Read the cleaned CSV file\n",
    "df = pd.read_csv(csv_file_path)\n",
    "\n",
    "# Check for missing values in blood group columns (O+, A+, B+, AB+, O-, A-, B-, AB-)\n",
    "blood_group_columns = ['O+', 'A+', 'B+', 'AB+', 'O-', 'A-', 'B-', 'AB-']\n",
    "\n",
    "# Identify rows with missing values in any of the blood group columns\n",
    "missing_values_df = df[df[blood_group_columns].isna().any(axis=1)]\n",
    "\n",
    "# Display the countries with missing blood group values\n",
    "print(\"Countries with missing blood group values:\")\n",
    "print(missing_values_df[['Country/Dependency']])\n",
    "\n",
    "# Optionally, save the result to a CSV file if you want to keep track of it\n",
    "output_csv_missing_values = \"F:/MLpractrice/blood/countries_with_missing_blood_group_values.csv\"\n",
    "missing_values_df.to_csv(output_csv_missing_values, index=False)\n",
    "\n",
    "print(f\"\\nThe countries with missing values have been saved to: {output_csv_missing_values}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "057901ff-efc6-4e75-9d6e-d530468a1538",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Country: Egypt\n",
      "Missing blood group(s): O-, A-, B-, AB-\n",
      "\n",
      "Country: Mongolia\n",
      "Missing blood group(s): AB+\n",
      "\n",
      "The countries with missing values have been saved to: F:/MLpractrice/blood/countries_with_missing_blood_group_values.csv\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "\n",
    "# Path to the cleaned CSV file\n",
    "csv_file_path = \"F:/MLpractrice/blood/cleaned_blood_type_distribution_by_country.csv\"\n",
    "\n",
    "# Read the cleaned CSV file\n",
    "df = pd.read_csv(csv_file_path)\n",
    "\n",
    "# Check for missing values in blood group columns (O+, A+, B+, AB+, O-, A-, B-, AB-)\n",
    "blood_group_columns = ['O+', 'A+', 'B+', 'AB+', 'O-', 'A-', 'B-', 'AB-']\n",
    "\n",
    "# Find rows where any blood group value is missing\n",
    "missing_values_df = df[df[blood_group_columns].isna().any(axis=1)]\n",
    "\n",
    "# Display which blood group values are missing for each country\n",
    "for index, row in missing_values_df.iterrows():\n",
    "    country = row['Country/Dependency']\n",
    "    missing_groups = [group for group in blood_group_columns if pd.isna(row[group])]\n",
    "    print(f\"\\nCountry: {country}\")\n",
    "    print(f\"Missing blood group(s): {', '.join(missing_groups)}\")\n",
    "\n",
    "# Optionally, save the result to a CSV file if you want to keep track of it\n",
    "output_csv_missing_values = \"F:/MLpractrice/blood/countries_with_missing_blood_group_values.csv\"\n",
    "missing_values_df.to_csv(output_csv_missing_values, index=False)\n",
    "\n",
    "print(f\"\\nThe countries with missing values have been saved to: {output_csv_missing_values}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "dc09429d-cbf7-4e15-8eb3-f7b00a89c78f",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
