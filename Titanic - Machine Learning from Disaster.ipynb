{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "86bfb486-8f3a-409d-a6f5-bfc6967a12cc",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "2"
      ]
     },
     "execution_count": 1,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#Shuvo Kumar Basak"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "fa45f490-0458-4be4-9b72-b4782d900593",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: pandas in d:\\anaconda3\\lib\\site-packages (2.1.4)\n",
      "Requirement already satisfied: numpy in d:\\anaconda3\\lib\\site-packages (1.26.4)\n",
      "Requirement already satisfied: matplotlib in d:\\anaconda3\\lib\\site-packages (3.8.0)\n",
      "Requirement already satisfied: seaborn in d:\\anaconda3\\lib\\site-packages (0.12.2)\n",
      "Requirement already satisfied: scikit-learn in d:\\anaconda3\\lib\\site-packages (1.2.2)\n",
      "Requirement already satisfied: python-dateutil>=2.8.2 in d:\\anaconda3\\lib\\site-packages (from pandas) (2.8.2)\n",
      "Requirement already satisfied: pytz>=2020.1 in d:\\anaconda3\\lib\\site-packages (from pandas) (2023.3.post1)\n",
      "Requirement already satisfied: tzdata>=2022.1 in d:\\anaconda3\\lib\\site-packages (from pandas) (2023.3)\n",
      "Requirement already satisfied: contourpy>=1.0.1 in d:\\anaconda3\\lib\\site-packages (from matplotlib) (1.2.0)\n",
      "Requirement already satisfied: cycler>=0.10 in d:\\anaconda3\\lib\\site-packages (from matplotlib) (0.11.0)\n",
      "Requirement already satisfied: fonttools>=4.22.0 in d:\\anaconda3\\lib\\site-packages (from matplotlib) (4.25.0)\n",
      "Requirement already satisfied: kiwisolver>=1.0.1 in d:\\anaconda3\\lib\\site-packages (from matplotlib) (1.4.4)\n",
      "Requirement already satisfied: packaging>=20.0 in d:\\anaconda3\\lib\\site-packages (from matplotlib) (23.1)\n",
      "Requirement already satisfied: pillow>=6.2.0 in d:\\anaconda3\\lib\\site-packages (from matplotlib) (10.2.0)\n",
      "Requirement already satisfied: pyparsing>=2.3.1 in d:\\anaconda3\\lib\\site-packages (from matplotlib) (3.0.9)\n",
      "Requirement already satisfied: scipy>=1.3.2 in d:\\anaconda3\\lib\\site-packages (from scikit-learn) (1.11.4)\n",
      "Requirement already satisfied: joblib>=1.1.1 in d:\\anaconda3\\lib\\site-packages (from scikit-learn) (1.2.0)\n",
      "Requirement already satisfied: threadpoolctl>=2.0.0 in d:\\anaconda3\\lib\\site-packages (from scikit-learn) (2.2.0)\n",
      "Requirement already satisfied: six>=1.5 in d:\\anaconda3\\lib\\site-packages (from python-dateutil>=2.8.2->pandas) (1.16.0)\n"
     ]
    }
   ],
   "source": [
    "!pip install pandas numpy matplotlib seaborn scikit-learn\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "c78a37f6-e52c-4d70-a194-6a2555677c5b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Logistic Regression Accuracy: 81.01%\n",
      "Random Forest Accuracy: 81.56%\n",
      "SVM Accuracy: 82.12%\n",
      "[[89 16]\n",
      " [17 57]]\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.84      0.85      0.84       105\n",
      "           1       0.78      0.77      0.78        74\n",
      "\n",
      "    accuracy                           0.82       179\n",
      "   macro avg       0.81      0.81      0.81       179\n",
      "weighted avg       0.82      0.82      0.82       179\n",
      "\n",
      "Submission file created successfully!\n"
     ]
    }
   ],
   "source": [
    "# Titanic Prediction Model\n",
    "\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "from sklearn.model_selection import train_test_split, cross_val_score\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.impute import SimpleImputer\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.svm import SVC\n",
    "from sklearn.metrics import accuracy_score, confusion_matrix, classification_report\n",
    "\n",
    "# Load the datasets\n",
    "train_df = pd.read_csv('F:/MLpractrice/taitanic/data/train.csv')\n",
    "test_df = pd.read_csv('F:/MLpractrice/taitanic/data/test.csv')\n",
    "\n",
    "# Display the first few rows of the train dataset\n",
    "train_df.head()\n",
    "\n",
    "# Data Cleaning and Preprocessing\n",
    "\n",
    "# Drop unnecessary columns\n",
    "train_df = train_df.drop(['PassengerId', 'Name', 'Ticket', 'Cabin'], axis=1)\n",
    "test_df = test_df.drop(['PassengerId', 'Name', 'Ticket', 'Cabin'], axis=1)\n",
    "\n",
    "# Fill missing values\n",
    "imputer = SimpleImputer(strategy='median')\n",
    "train_df['Age'] = imputer.fit_transform(train_df[['Age']])\n",
    "test_df['Age'] = imputer.transform(test_df[['Age']])\n",
    "\n",
    "# Fill Embarked with the most common value\n",
    "train_df['Embarked'] = train_df['Embarked'].fillna(train_df['Embarked'].mode()[0])\n",
    "test_df['Embarked'] = test_df['Embarked'].fillna(test_df['Embarked'].mode()[0])\n",
    "\n",
    "# Fill Fare missing values in the test dataset\n",
    "test_df['Fare'] = imputer.fit_transform(test_df[['Fare']])\n",
    "\n",
    "# Convert categorical variables to dummy variables\n",
    "train_df = pd.get_dummies(train_df, columns=['Sex', 'Embarked'], drop_first=True)\n",
    "test_df = pd.get_dummies(test_df, columns=['Sex', 'Embarked'], drop_first=True)\n",
    "\n",
    "# Split the data into features and target variable\n",
    "X = train_df.drop('Survived', axis=1)\n",
    "y = train_df['Survived']\n",
    "\n",
    "# Split the data into training and validation sets\n",
    "X_train, X_val, y_train, y_val = train_test_split(X, y, test_size=0.2, random_state=42)\n",
    "\n",
    "# Feature Scaling\n",
    "scaler = StandardScaler()\n",
    "X_train = scaler.fit_transform(X_train)\n",
    "X_val = scaler.transform(X_val)\n",
    "test_df = scaler.transform(test_df)\n",
    "\n",
    "# Model Training\n",
    "\n",
    "# Logistic Regression\n",
    "logreg = LogisticRegression()\n",
    "logreg.fit(X_train, y_train)\n",
    "y_pred_logreg = logreg.predict(X_val)\n",
    "accuracy_logreg = accuracy_score(y_val, y_pred_logreg)\n",
    "print(f'Logistic Regression Accuracy: {accuracy_logreg * 100:.2f}%')\n",
    "\n",
    "# Random Forest Classifier\n",
    "rf = RandomForestClassifier(n_estimators=100)\n",
    "rf.fit(X_train, y_train)\n",
    "y_pred_rf = rf.predict(X_val)\n",
    "accuracy_rf = accuracy_score(y_val, y_pred_rf)\n",
    "print(f'Random Forest Accuracy: {accuracy_rf * 100:.2f}%')\n",
    "\n",
    "# Support Vector Machine\n",
    "svc = SVC()\n",
    "svc.fit(X_train, y_train)\n",
    "y_pred_svc = svc.predict(X_val)\n",
    "accuracy_svc = accuracy_score(y_val, y_pred_svc)\n",
    "print(f'SVM Accuracy: {accuracy_svc * 100:.2f}%')\n",
    "\n",
    "# Evaluate the best model (e.g., Random Forest)\n",
    "print(confusion_matrix(y_val, y_pred_rf))\n",
    "print(classification_report(y_val, y_pred_rf))\n",
    "\n",
    "# Make predictions on the test dataset with the best model\n",
    "predictions = rf.predict(test_df)\n",
    "\n",
    "# Prepare the submission file\n",
    "submission = pd.read_csv('F:/MLpractrice/taitanic/data/gender_submission.csv')\n",
    "submission['Survived'] = predictions\n",
    "submission.to_csv('F:/MLpractrice/taitanic/data/submission.csv', index=False)\n",
    "\n",
    "print(\"Submission file created successfully!\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1e5eafe2-9f59-42c0-a8c6-1b459eafe151",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0aff89b5-1cfa-4caa-ab92-dc704b6b4667",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cb599859-a3b5-46ef-acdc-8efd54f63b27",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "79e5c5f3-2311-4e74-9238-033a798e86b8",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "13dcbfce-693c-4fe4-abf9-cb7676468cdf",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "dbe90940-1cd6-4c99-9fa2-af24f9e792db",
   "metadata": {},
   "outputs": [
    {
     "ename": "ModuleNotFoundError",
     "evalue": "No module named 'tensorflow'",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mModuleNotFoundError\u001b[0m                       Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[1], line 7\u001b[0m\n\u001b[0;32m      5\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01msklearn\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mlinear_model\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m LogisticRegression\n\u001b[0;32m      6\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01msklearn\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mmetrics\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m accuracy_score, classification_report\n\u001b[1;32m----> 7\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01mtensorflow\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mkeras\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mpreprocessing\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mtext\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m Tokenizer\n\u001b[0;32m      8\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01mtensorflow\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mkeras\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mpreprocessing\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01msequence\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m pad_sequences\n\u001b[0;32m      9\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01mtensorflow\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mkeras\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mmodels\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m Sequential\n",
      "\u001b[1;31mModuleNotFoundError\u001b[0m: No module named 'tensorflow'"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.feature_extraction.text import TfidfVectorizer\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.metrics import accuracy_score, classification_report\n",
    "from tensorflow.keras.preprocessing.text import Tokenizer\n",
    "from tensorflow.keras.preprocessing.sequence import pad_sequences\n",
    "from tensorflow.keras.models import Sequential\n",
    "from tensorflow.keras.layers import Embedding, LSTM, Dense, Dropout, Bidirectional\n",
    "from tensorflow.keras.optimizers import Adam\n",
    "import joblib\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a4b8f2d4-4061-439c-b63a-55bd7fab777e",
   "metadata": {},
   "outputs": [],
   "source": [
    "!pip install pandas numpy scikit-learn tensorflow keras\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4df1e8c4-aeb0-496d-8f3a-77827a4cc5e5",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
